{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb8957f",
   "metadata": {},
   "source": [
    "Load ENV vairables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1ee12f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import config\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af1086b",
   "metadata": {},
   "source": [
    "Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00670d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai, langchain\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "847958d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.8'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53243e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48d8f3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"Hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e5d68b",
   "metadata": {},
   "source": [
    "LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f499b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nI'm doing well, thanks for asking. How are you?\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "\n",
    "llm.predict(\"How are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0e3771",
   "metadata": {},
   "source": [
    "Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4362bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: How are you today?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hi there! I'm doing great, thanks for asking. I'm feeling very productive and I've been learning a lot of new things. How about you?\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.run(\"How are you today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d280fdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: How are you today?\n",
      "AI:  Hi there! I'm doing great, thanks for asking. I'm feeling very productive and I've been learning a lot of new things. How about you?\n",
      "Human: Do you remember my previous question?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Absolutely! You asked me how I am today.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Do you remember my previous question?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "740071a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nYes, your previous question was: \"Do you have any questions about the product?\".'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"DO you remember my previous question?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61810b01",
   "metadata": {},
   "source": [
    "Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df5f442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Return 5 the country names starting with the same first character as: {country}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['country'],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "baf68261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], template='\\nReturn 5 the country names starting with the same first character as: {country}\\n\\n')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ccf5d958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Return 5 the country names starting with the same first character as: India\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n1. Indonesia \\n2. Ireland \\n3. Iran \\n4. Iceland \\n5. Italy'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.run(\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8be737e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatMessagePromptTemplate,\n",
    "    ChatPromptTemplate\n",
    ")\n",
    "\n",
    "system_template = \"\"\"\n",
    "You are an historian with extensive knowledge about the world history. Users might ask you about any historical event in last two decades.\n",
    "You job is to return only a one paragraph summry of the requested event if you know about it. Do create any details about that event \n",
    "which are not accurate.\n",
    "\"\"\"\n",
    "\n",
    "human_template = \"\"\" {event} \"\"\"\n",
    "\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    system_template\n",
    ")\n",
    "human_message = HumanMessagePromptTemplate.from_template(\n",
    "    human_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca97db69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='\\nYou are an historian with extensive knowledge about the world history. Users might ask you about any historical event in last two decades.\\nYou job is to return only a one paragraph summry of the requested event if you know about it. Do create any details about that event \\nwhich are not accurate.\\n'))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f7c8d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['event'], template=' {event} '))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6750bcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are an historian with extensive knowledge about the world history. Users might ask you about any historical event in last two decades.\n",
      "You job is to return only a one paragraph summry of the requested event if you know about it. Do create any details about that event \n",
      "which are not accurate.\n",
      "\n",
      "Human:  2011 Cricket World Cup \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nSystem: The 2011 Cricket World Cup was held in India, Sri Lanka, and Bangladesh from February 19th to April 2nd. It was the tenth edition of the Cricket World Cup, and was won by India, who defeated Sri Lanka in the final at the Wankhede Stadium in Mumbai. It was the first time in history that a host nation won the tournament, and marked the first time that India won the cup since 1983. The tournament featured a total of 49 matches, including two semi-finals and a final.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message, human_message\n",
    "])\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=combined_prompt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.run(\"2011 Cricket World Cup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a51e5b",
   "metadata": {},
   "source": [
    "Output Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aacc619",
   "metadata": {},
   "source": [
    "Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "62904706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are an historian with extensive knowledge about the world history. Users might ask you about any historical event in last two decades.\n",
      "You job is to return only a one paragraph summry of the requested event if you know about it. Do create any details about that event \n",
      "which are not accurate.\n",
      "\n",
      "Human:  2019 Fifa World Cup \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"System: The 2019 FIFA World Cup was held in France from June 7 to July 7, 2019. It was the eighth edition of the FIFA Women's World Cup and the second to be held in France, after the 1999 tournament. The tournament featured 24 teams, including the defending champions, the United States. The tournament was won by the United States, who beat the Netherlands 2-0 in the final. The tournament was widely praised for its increased standard of play, and for the high level of competitiveness between teams.\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "\n",
    "class Clean_LLM_Text(BaseOutputParser):\n",
    "    \n",
    "    def parse(self, text):\n",
    "        output = text.strip()\n",
    "        return output\n",
    "    \n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=combined_prompt,\n",
    "    verbose=True,\n",
    "    output_parser=Clean_LLM_Text()\n",
    ")\n",
    "\n",
    "chain.run(\"2019 Fifa World Cup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8588d44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are an historian with extensive knowledge about the world history. Users might ask you about any historical event in last two decades.\n",
      "You job is to return only a one paragraph summry of the requested event if you know about it. Do create any details about that event \n",
      "which are not accurate.\n",
      "\n",
      "Human:  2016 Election \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are an historian with extensive knowledge about the world history. Users might ask you about any historical event in last two decades.\n",
      "You job is to return only a one paragraph summry of the requested event if you know about it. Do create any details about that event \n",
      "which are not accurate.\n",
      "\n",
      "Human:  2013 Lok-sabha Election \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "input_list = [\n",
    "    {\n",
    "        \"event\": \"2016 Election\"\n",
    "    },\n",
    "    {\n",
    "        \"event\": \"2013 Lok-sabha Election\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response = chain.apply(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ebfe270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'System: The 2016 United States presidential election was held on November 8, 2016. The Republican ticket of businessman Donald Trump and Indiana Governor Mike Pence defeated the Democratic ticket of former Secretary of State Hillary Clinton and U.S. Senator from Virginia Tim Kaine. Trump took office as the 45th President, and Pence as the 48th Vice President, on January 20, 2017. It was the 58th quadrennial U.S. presidential election, and was the fifth time in U.S. history that the winning candidate lost the popular vote, the second time a Republican candidate did so.'},\n",
       " {'text': 'System: The 2013 Indian general election was held to constitute the 16th Lok Sabha, electing members of parliament for all 543 parliamentary constituencies of India. The main contenders in the election were the Indian National Congress (INC) and the Bharatiya Janata Party (BJP). The INC won a total of 206 seats, while the BJP won a total of 282 seats. The election also saw the emergence of the Aam Aadmi Party (AAP), which won four seats. The election was held in nine phases between 7 April and 12 May.'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e51f7f",
   "metadata": {},
   "source": [
    "Simple Chain Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "99eea73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "identifer_template = \"\"\"\n",
    "You are a export in the field of general knowledge.\n",
    "Your only job is to identify a real or reel world personality based on the asked question by the user.\n",
    "Your only response should be the name of the personality.\n",
    "\n",
    "Name: {name}\n",
    "\"\"\"\n",
    "\n",
    "identifier_chain = LLMChain.from_string(\n",
    "    llm=llm,\n",
    "    template=identifer_template\n",
    ")\n",
    "\n",
    "personality = identifier_chain.run(\"Who was the last CEO of Google?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "09c4e8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: Sundar Pichai'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "96040d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An Indian-American technology executive, currently the CEO of Google and its parent company Alphabet.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_template = \"\"\"\n",
    "You are a export in the field of general knowledge.\n",
    "Your only job is to give a strictly two line description of the asked personality by the user.\n",
    "\n",
    "Personality: {person}\n",
    "\"\"\"\n",
    "description_chain = LLMChain.from_string(\n",
    "    llm=llm,\n",
    "    template=description_template\n",
    ")\n",
    "\n",
    "description_chain.run(personality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "07a92169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mAnswer: Barry Bonds\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mBarry Bonds is a former Major League Baseball outfielder and one of the most prolific home run hitters in history, setting the record for most career home runs.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Barry Bonds is a former Major League Baseball outfielder and one of the most prolific home run hitters in history, setting the record for most career home runs.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(\n",
    "    chains=[identifier_chain, description_chain],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.run(\"Who holds the record for most number of home runs in base ball?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain Hands On",
   "language": "python",
   "name": "langchain_hands_on"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
